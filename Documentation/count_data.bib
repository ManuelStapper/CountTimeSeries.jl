% Encoding: UTF-8

@Article{aeberhard_2014,
  author    = {Aeberhard, W.H. and Cantoni, E. and Heritier, S.},
  title     = {Robust Inference in the Negative Binomial Regression Model with an Application to Falls Data},
  journal   = {Biometrics},
  year      = {2014},
  volume    = {70},
  number    = {4},
  pages     = {920--931},
  month     = dec,
  abstract  = {A popular way to model overdispersed count data, such as the number of falls reported during intervention
studies, is by means of the negative binomial (NB) distribution. Classical estimating methods are well-known to be sensitive
to model misspecifications, taking the form of patients falling much more than expected in such intervention studies where
the NB regression model is used. We extend in this article two approaches for building robust M-estimators of the regression
parameters in the class of generalized linear models to the NB distribution. The first approach achieves robustness in the
response by applying a bounded function on the Pearson residuals arising in the maximum likelihood estimating equations,
while the second approach achieves robustness by bounding the unscaled deviance components. For both approaches, we
explore different choices for the bounding functions. Through a unified notation, we show how close these approaches may
actually be as long as the bounding functions are chosen and tuned appropriately, and provide the asymptotic distributions
of the resulting estimators. Moreover, we introduce a robust weighted maximum likelihood estimator for the overdispersion
parameter, specific to the NB distribution. Simulations under various settings show that redescending bounding functions
yield estimates with smaller biases under contamination while keeping high efficiency at the assumed model, and this for
both approaches. We present an application to a recent randomized controlled trial measuring the effectiveness of an exercise
program at reducing the number of falls among people suffering from Parkinsons disease to illustrate the diagnostic use of
such robust procedures and their need for reliable inference.},
  doi       = {10.1111/biom.12212},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\aeberhard_2014.pdf:PDF},
  keywords  = {Bounded influence function, negative binomial regression, overdispersed count data, redescending estimators, weightes maximum likelihood},
  publisher = {Wiley-Blackwell},
}

@Unpublished{aeberhard_2001,
  author    = {Agostinelli, C. and Markatou, M.},
  title     = {TEST OF HYPOTHESES BASED ON THE WEIGHTED LIKELIHOOD METHODOLOGY},
  month     = apr,
  year      = {2001},
  abstract  = {Weighted versions of the likelihood ratio, Wald, score are proposed for parametric inference. If the parametric model weighted likelihood tests are asymptotically equivalent to the corresponding hood based tests, while the disparity test has asymptotically the as that of ... where ... are standard normal random variables eigenvalues of an appropriate matrix. The tests have high level down points and they perform well in finite samples. A simulation data example illustrate the performance of the tests in the presence and asymmetric contamination.},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\agostinelli_2001.pdf:PDF},
  keywords  = {Asymptotic distribution, breakdown function, likelihood ratio test, robusness, score test, Wald test, weighted likelihood},
  number    = {2},
  pages     = {499-514},
  publisher = {Institute of Statistical Sciences, Academia Sincia},
  url       = {http://www.jstor.org/stable/24306874},
  volume    = {11},
}

@Unpublished{agostinelli_2003,
  author       = {Agostinelli, C.},
  title        = {Robust Time Series Estimation via Weighted LIKELIHOOD},
  year         = {2003},
  abstract     = {In this paper we introduce a method for efficient and robust estimation of the unknown parameters of an autoregressive-moving average model based on weighted likelihood. Two types of outliers, i.e. additive and innovation, are taken into account without knowing their number position or intensity. A new procedure is used to classify the outliers and to bound the impact of additive outliers in order to inprove the breakdown point of the method. Two examples and a Monte Carlo siulation are presented.},
  file         = {:C\:\\Users\\stapperm\\Documents\\Paper\\agostinelli_2003.pdf:PDF},
  keywords     = {Additive outliers, Autoregressive-moving average, Innovation outliers, weighted likelihood},
  organization = {Department of Statistics, University of Venezia, Italy},
}

@Article{agostinelli_2006,
  author    = {Agostinelli, C.},
  title     = {Notes on Pearson residuals and weighted likelihood estimating equations},
  journal   = {Statistics {\&} Probability Letters},
  year      = {2006},
  volume    = {76},
  number    = {17},
  pages     = {1930--1934},
  month     = {nov},
  abstract  = {In these notes we show that the Pearson residuals (PR) [Lindsay, B.G., 1994. Efficiency versus robustness: the case for
minimum Hellinger distance and related methods. Ann. Statist. 22, 1018–1114.] have a natural asymptotic lower bound
under the gross error model which can be used in the problem of choosing a root when multiple roots are present in the
weighted likelihood estimating equations. Further, we show through an example how the minimum of the PR plays an
important role in the robust estimation approach based on weighted likelihood.},
  doi       = {10.1016/j.spl.2006.04.048},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\agostinelli_2006.pdf:PDF},
  keywords  = {Pearson residuals; Weighted likelihood estimating equations�},
  publisher = {Elsevier {BV}},
}

@Article{agostinelli_2010,
  author    = {Agostinelli, C. and Bisaglia, L.},
  title     = {{ARFIMA} processes and outliers: a weighted likelihood approach},
  journal   = {Journal of Applied Statistics},
  year      = {2010},
  volume    = {37},
  number    = {9},
  pages     = {1569--1584},
  month     = {sep},
  abstract  = {In this paper, we consider the problem of robust estimation of the fractional parameter, d, in long memory autoregressive fractionally integrated moving average processes, when two types of outliers, i.e. additive and innovation, are taken into account without knowing their number, position or intensity. The proposed method is a weighted likelihood estimation (WLE) approach for which needed deﬁnitions and algorithm are given. By an extensive Monte Carlo simulation study, we compare the performance of the WLE method with the performance of both the approximated maximum likelihood estimation (MLE) and the robust M-estimator proposed by Beran (Statistics for Long-Memory Processes, Chapman & Hall, London, 1994). We ﬁnd that robustness against the two types of considered outliers can be achieved without loss of efﬁciency. Moreover, as a byproduct of the procedure, we can classify the suspicious observations in different kinds of outliers. Finally, we apply the proposed methodology to the Nile River annual minima time series.},
  doi       = {10.1080/02664760903093609},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\agostinelli_2010.pdf:PDF},
  keywords  = {ARFIMA processes, outliers, robust estimation, weighted likelihood},
  publisher = {Informa {UK} Limited},
}

@Book{amemiya_1985,
  title     = {Advanced Econometrics},
  publisher = {Harvard University Press},
  year      = {1985},
  author    = {Amemiya, T.},
  isbn      = {978-0674005600},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\amemiya_1985.pdf:PDF},
  keywords  = {econometics, asymptotics, limiting distribution},
}

@Article{basu_1998,
  author   = {Basu, A. and Harris, I.R. and Hjort, N.L. and Jones, M.C.},
  title    = {Robust and efficient estimation by minimising a density and power divergence},
  journal  = {Biometrika},
  year     = {1998},
  volume   = {85},
  number   = {3},
  pages    = {549--559},
  month    = sep,
  doi      = {10.1093/biomet/85.3.535},
  file     = {:C\:\\Users\\stapperm\\Documents\\Paper\\Basu_1998.pdf:PDF},
  keywords = {Asmptotic efficiency, influence funtion, M-estimation, Maximum Likelihood, Minimum Distance Estimation, Robustness},
  url      = {https://doi.org/10.1093/biomet/85.3.535},
}

@Article{cantoni_2001,
  author    = {Cantoni, E. and Ronchetti, E.},
  title     = {Robust Inference for Generalized Linear Models},
  journal   = {Journal of the American Statistical Association},
  year      = {2001},
  volume    = {96},
  number    = {455},
  pages     = {1022--1030},
  month     = {sep},
  abstract  = {By starting from a natural class of robust estimators for generalized linear models based on the notion of quasi-likelihood, we de ne
robust deviances that can be used for stepwise model selection as in the classical framework. We derive the asymptotic distribution of
tests based on robust deviances, and we investigate the stability of their asymptotic level under contamination. The binomial and Poisson
models are treated in detail. Two applications to real data and a sensitivity analysis show that the inference obtained by means of the
new techniques is more reliable than that obtained by classical estimation and testing procedures.},
  doi       = {10.1198/016214501753209004},
  file      = {:cantoni_2001 - Robust Inference for Generalized Linear Models:;:\:\\Users\\stapperm\\Documents\\Paper\\cantoni_2001.pdf:PDF},
  keywords  = {Binomial regression; In uence function; M-estimators; Model selection; Poisson regression; Quasi-likehood; Robust deviance; Robustness of ef ciency; Robustness of validity.},
  publisher = {Informa {UK} Limited},
}

@Unpublished{duerre_2014,
  author   = {Duerre, A. and Fried, R. and Liboschik, T.},
  title    = {Robust estimation of (partial) autocorrelation},
  note     = {SFB 823 Discussion paper 12/14},
  month    = apr,
  year     = {2014},
  abstract = {The autocorrelation function (acf) and the partial autocorrelation function (pacf) are
elementary tools of linear time series analysis. The sensitivity of the conventional sample
acf and pacf to outliers is well known. We review robust estimators and evaluate their
performances in different data situations considering Gaussian scenarios with and without
outliers in a simulation study.},
  file     = {:C\:\\Users\\stapperm\\Documents\\Paper\\duerre_2015.pdf:PDF},
  keywords = {Autocovariance, outliers, time series, correlogram�},
}

@Article{elsaied_2014,
  author    = {Elsaied, H. and Fried, R.},
  title     = {Robust Fitting of {INARCH} Models},
  journal   = {Journal of Time Series Analysis},
  year      = {2014},
  volume    = {35},
  number    = {6},
  pages     = {517--535},
  month     = {jun},
  abstract  = {We discuss robust M-estimation of INARCH models for count time series. These models assume the observation at each
point in time to follow a Poisson distribution conditionally on the past, with the conditional mean being a linear function
of previous observations. This simple linear structure allows us to transfer M-estimators for autoregressive models to this
situation, with some simplifications being possible because the conditional variance given the past equals the conditional mean.
We investigate the performance of the resulting generalized M-estimators using simulations. The usefulness of the proposed
methods is illustrated by real data examples.},
  doi       = {10.1111/jtsa.12079},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\elsaied_2014.pdf:PDF},
  keywords  = {Count data; Poisson model; INARCH models; GLM models; Huber M-estimator; Tukey M-estimator; transient shifts; additive outliers; robustness},
  publisher = {Wiley-Blackwell},
}

@PhdThesis{elsaied_diss_2012,
  author   = {Elsaied, H.},
  title    = {Robust Modelling of Count Data},
  school   = {TU Dortmund},
  year     = {2012},
  type     = {phdthesis},
  month    = jan,
  abstract = {M-estimators as modified versions of maximum likelihood estimators and their asymptotic
properties play an important role in the development of modern robust statistics
since the 1960s. In our thesis, we construct new M-estimators based on Tukey’s bisquare
function to fit count data robustly. The Poisson distribution provides a standard framework
for the analysis of this type of data.
In case of independent identically distributed Poisson data, M-estimators based on the
Huber and Tukey’s bisquare function are compared to already existing estimators implemented
in R via simulations in case of clean data and of additive outliers. It turns out
that it is difficult to combine high robustness against outliers and high efficiency under
ideal conditions if the Poisson parameter is small, because such Poisson distributions are
highly skewed. We suggest an alternative estimator based on adaptively trimmed means
as a possible solution to this problem. Our simulation results indicate that a modified
version of the R-function glmrob with external weights gives the best robustness properties
among all estimation procedures based on the Huber function. A new modified
Tukey M-estimator provides improvements over the other procedures which depend on
the Tukey function and also those which depend on the Huber function, particularly in
case of moderately large and very large outliers. The estimator based on adaptive trimming
provides even better results at small Poisson means.
Furthermore, our work constitutes a first treatment of robust M-estimation of INGARCH
models for count time series. These models assume the observation at each point in time
to follow a Poisson distribution conditionally on the past, with the conditional mean
being a linear function of previous observations and past conditional means. We focus
on the INGARCH(1,0) model as the simplest interesting variant. Our approach based
on Tukey’s bisquare function with bias correction and initialization from a robust AR(1)
fit provides good efficiencies in case of clean data. In the presence of outliers, the biascorrected
Tukey M-estimators perform better than the uncorrected ones and the conditional
maximum likelihood estimator. The construction of adequate Tukey M-estimators
or the development of other robust estimators for INGARCH models of higher orders
remains an open problem, albeit some preliminary investigations for the INGARCH(1,1)
model are presented here.
Some applications to real data from the medical field and artificial data examples indicate
that the INGARCH(1,0) model is a promising candidate for such data, and that the issue
of robust estimation tackled here is important.},
  file     = {:C\:\\Users\\stapperm\\Documents\\Paper\\elsaied_diss_2012.pdf:PDF},
  keywords = {Count data, robust estimation, poisson model, INGARCH, GLM, M-estimator, Robustness, Asymptotic properties, medical application},
}

@Article{ferland_2006,
  author    = {Ferland, R. and Latour, A. and Oraichi, D.},
  title     = {Integer-Valued {GARCH} Process},
  journal   = {Journal of Time Series Analysis},
  year      = {2006},
  volume    = {27},
  number    = {6},
  pages     = {923--942},
  month     = {nov},
  abstract  = {An integer-valued analogue of the classical generalized autoregressive
conditional heteroskedastic (GARCH) (p,q) model with Poisson deviates is proposed and
a condition for the existence of such a process is given. For the case p ¼ 1, q ¼ 1, it is
explicitly shown that an integer-valuedGARCHprocess is a standard autoregressive moving
average (1, 1) process. The problem of maximum likelihood estimation of parameters is
treated. An application of the model to a real time series with a numerical example is given.},
  doi       = {10.1111/j.1467-9892.2006.00496.x},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\ferland_2006.pdf:PDF},
  keywords  = {Integer-valued time series; GARCH model; heteroskedastic},
  publisher = {Wiley-Blackwell},
}

@Article{fokianos_2009,
  author    = {Fokianos, K. and Rahbek, A. and Tj{\o}stheim, D.},
  title     = {Poisson Autoregression},
  journal   = {Journal of the American Statistical Association},
  year      = {2009},
  volume    = {104},
  number    = {488},
  pages     = {1430--1439},
  month     = {dec},
  abstract  = {In this article we consider geometric ergodicity and likelihood-based inference for linear and nonlinear Poisson autoregression. In the linear
case, the conditional mean is linked linearly to its past values, as well as to the observed values of the Poisson process. This also applies to the
conditional variance, making possible interpretation as an integer-valued generalized autoregressive conditional heteroscedasticity process.
In a nonlinear conditional Poisson model, the conditional mean is a nonlinear function of its past values and past observations. As a particular
example, we consider an exponential autoregressive Poisson model for time series. Under geometric ergodicity, the maximum likelihood
estimators are shown to be asymptotically Gaussian in the linear model. In addition, we provide a consistent estimator of their asymptotic
covariance matrix. Our approach to verifying geometric ergodicity proceeds via Markov theory and irreducibility. Finding transparent
conditions for proving ergodicity turns out to be a delicate problem in the original model formulation. This problem is circumvented by
allowing a perturbation of the model. We show that as the perturbations can be chosen to be arbitrarily small, the differences between the
perturbed and nonperturbed versions vanish as far as the asymptotic distribution of the parameter estimates is concerned. This article has
supplementary material online.},
  doi       = {10.1198/jasa.2009.tm08270},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\fokianos_2009.pdf:PDF},
  keywords  = {irreducibility; Asymptotic theory; Count data; Generalized linear model; Geometric ergodicity; Integer generalized autoregressive conditional heteroscedasticity; Likelihood; Noncanonical link function; Observation-driven model; Poisson regression.},
  publisher = {Informa {UK} Limited},
}

@Unpublished{fokianos_fried_2009,
  author   = {Fokianos, K. and Fried, R.},
  title    = {Interventions in INGARCH processes},
  month    = jun,
  year     = {2009},
  abstract = {We study the problem of intervention effects generating various types of outliers in a linear count time series
model. This model belongs to the class of observation driven models and extends the class of Gaussian
linear time series models within the exponential family framework. Studies about effects of covariates and
interventions for count time series models have largely fallen behind due to the fact that the underlying
process, whose behavior determines the dynamics of the observed process, is not observed. We suggest a
computationally feasible approach to these problems, focusing especially on the detection and estimation of
sudden shifts and outliers. To identify successfully such unusual events we employ the maximum of score
tests, whose critical values in finite samples are determined by parametric bootstrap. The usefulness of the
proposed methods is illustrated using simulated and real data examples.},
  file     = {:C\:\\Users\\stapperm\\Documents\\Paper\\fokianos_fried_2009.pdf:PDF},
  keywords = {parametric bootstrap; generalized linear models; observation driven models; level shifts; transient shifts; outliers.},
}

@Book{hallheyde_1980,
  title     = {Martingale Limit Theory and its Application},
  publisher = {Academic Press},
  year      = {1980},
  author    = {Hall, P. and Heyde, C.C.},
  isbn      = {978-1483240244},
  note      = {For the definition of stochastic convergence},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\hallheyde_1980.pdf:PDF},
  keywords  = {Martingale, Limit theory, convergence theorem},
}

@Article{jensenrahbek_2007,
  author   = {Jensen, S.T. and Rahbek, A.},
  title    = {On the Law of Large Numbers for (Geometrically) Ergodic Markov Chains},
  journal  = {Econometric Theory},
  year     = {2007},
  volume   = {23},
  number   = {4},
  pages    = {761--766},
  month    = aug,
  note     = {For the theorem: ergodic markov chain, measurable function, still ergodic under what condition?},
  file     = {:C\:\\Users\\stapperm\\Documents\\Paper\\jensenrahbek_2007.pdf:PDF},
  keywords = {markov chains, ergodicity, LLN},
}

@Article{kang_2014,
  author    = {Kang, J. and Lee, S.},
  title     = {Minimum density power divergence estimator for Poisson autoregressive models},
  journal   = {Computational Statistics {\&} Data Analysis},
  year      = {2014},
  volume    = {80},
  pages     = {44--56},
  month     = {dec},
  abstract  = {The robust estimation for Poisson autoregressive models is studied. As a robust estimator,
a minimum density power divergence estimator (MDPDE) is considered. It is shown that
under regularity conditions, the MDPDE is strongly consistent and asymptotically normal.
Simulation results are provided for illustration. A real data analysis is implemented for the
polio incidence data.},
  doi       = {10.1016/j.csda.2014.06.009},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\kang_2014.pdf:PDF},
  keywords  = {Density-based divergence measures Robust estimation Poisson autoregressive model Integer-valued GARCH model Consistency Asymptotic normality},
  publisher = {Elsevier {BV}},
}

@Article{kang_2015,
  author    = {Kang, J. and Song, J.},
  title     = {Robust parameter change test for Poisson autoregressive models},
  journal   = {Statistics {\&} Probability Letters},
  year      = {2015},
  volume    = {104},
  pages     = {14--21},
  month     = {sep},
  abstract  = {This study considers the problem of testing for a parameter change in Poisson autoregressive
models in the presence of outliers. For this purpose, we propose a cumulative sum test
based on the robust estimator introduced by Kang and Lee (2014a), and derive its limiting
null distribution. Simulation results demonstrate the robust properties of the proposed test.},
  doi       = {10.1016/j.spl.2015.04.027},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\kang_2015.pdf:PDF},
  keywords  = {Poisson autoregressive model Test for parameter change Robust test Outliers Minimum density power divergence estimator},
  publisher = {Elsevier {BV}},
}

@Article{kitromilidou_2015,
  author    = {Kitromilidou, S. and Fokianos, K.},
  title     = {Mallows' quasi-likelihood estimation for log-linear Poisson autoregressions},
  journal   = {Statistical Inference for Stochastic Processes},
  year      = {2015},
  volume    = {19},
  number    = {3},
  pages     = {337--361},
  month     = {dec},
  abstract  = {We consider the problems of robust estimation and testing for a log-linear model
with feedback for the analysis of count time series. We study inference for contaminated
data with transient shifts, level shifts and additive outliers. It turns out that the case of
additive outliers deserves special attention. We propose a robust method for estimating the
regression coefficients in the presence of interventions. The resulting robust estimators are
asymptotically normally distributed under some regularity conditions. A robust score type
test statistic is also examined. The methodology is applied to real and simulated data.},
  doi       = {10.1007/s11203-015-9131-z},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\kitromilidou_2015.pdf:PDF},
  keywords  = {Autocorrelation · Estimating equations · Generalized linear models · Integer valued time series · Interventions · Robust estimation},
  publisher = {Springer Nature},
}

@Unpublished{kitromilidou_2016,
  author   = {Kitromilidou, S. and Fokianos, K.},
  title    = {Robust Estimation Methods for a Class of Log-Linear Count},
  month    = mar,
  year     = {2014},
  abstract = {We study robust estimation of a log-linear Poisson model for count time series analysis. More specifically,
we study robust versions of maximum likelihood estimators under three different forms of interventions:
additive outliers, transient shifts and level shifts. We estimate the parameters using the maximum likelihood
estimator, the conditionally unbiased bounded-influence estimator and the Mallows quasi-likelihood
estimator and compare all three estimators in terms of their mean square error, bias and mean absolute error.
Our empirical results illustrate that under a level shift or a transient shift there are no significant
differences among the three estimators and the most interesting results are obtained in the presence of
additive outliers. The results are complemented by a real data example.},
  file     = {:C\:\\Users\\stapperm\\Documents\\Paper\\kitromilidou_2016.pdf:PDF},
  keywords = {autocorrelation; canonical link; conditionally unbiased bounded influence estimator; interven},
}

@PhdThesis{kitromilidou_diss_2015,
  author       = {Kitromilidou, S.},
  title        = {Robust Inference for log-linear Count Time Series Modes},
  school       = {University of Cyprus},
  year         = {2015},
  type         = {phdthesis},
  month        = oct,
  file         = {:C\:\\Users\\stapperm\\Documents\\Paper\\kitromilidou_diss_2015.pdf:PDF},
  keywords     = {robustness, log-linear, count data, poisson, autoregression},
  organization = {Department of Methematics and Statistics - University of Cyprus},
}

@Article{li_2016,
  author    = {Li, Q. and Lian, H. and Zhu, F.},
  title     = {Robust closed-form estimators for the integer-valued {GARCH} (1,1) model},
  journal   = {Computational Statistics {\&} Data Analysis},
  year      = {2016},
  volume    = {101},
  pages     = {209--225},
  month     = {sep},
  abstract  = {A closed-form estimator and its several robust versions for the integer-valued GARCH(1, 1)
model are proposed. These estimators are easy to implement and do not require the use
of any numerical optimization procedure. Consistency and asymptotic normality for the
non-robust closed-form estimator is established. The robustification of the closed-form estimator
is done by replacing the sample mean and autocorrelations by robust estimators
of them, respectively. The performances of these closed-form estimators are investigated
and compared via simulations. New estimators are applied to 5 stock-market data sets with
different periods and time intervals, and their prediction performances are assessed by
in-sample prediction, out-of-sample prediction and scoring rules. Other possible proposals
related to the closed-form estimators are also discussed},
  doi       = {10.1016/j.csda.2016.03.006},
  file      = {:C\:\\Users\\stapperm\\Documents\\Paper\\li_2016.pdf:PDF},
  keywords  = {Autocorrelation function Closed-form estimator Robustness Time series of counts},
  publisher = {Elsevier {BV}},
}

@PhdThesis{liboschik_diss_2016,
  author   = {Liboschik, T.},
  title    = {Modeling Count Time Series Following Generalized Linear Models},
  school   = {TU Dortmund},
  year     = {2016},
  type     = {phdthesis},
  month    = jul,
  file     = {:liboschik_diss_2016.pdf:PDF},
  keywords = {Count data, generalized linear model},
}

@Article{lindsay_1994,
  author   = {Lindsay, B.G.},
  title    = {Efficiency Versus Robustness: The Case for Minimum Hellinger Distance and Related Methods},
  journal  = {The Annaly of Statistics},
  year     = {1994},
  volume   = {22},
  number   = {2},
  pages    = {1081--1114},
  month    = jun,
  abstract = {It is shown how and why the influence curve poorly measures the
robustness properties of minimum Hellinger distance estimation. Rather,
for this and related forms of estimation, there is another function, the residual
adjustment function, that carries the relevant information about the
trade-off between efficiency and robustness. It is demonstrated that this
function determines various second-order measures of efficiency and robustness
through a scalar measure called the estimation curvature. The function
is also shown to determine the breakdown properties of the estimators
through its tail behavior. A 50% breakdown result is given. It is shown how
to create flexible classes of estimation methods in the spirit of M-estimation,
but with first-order efficiency (or even second-order efficiency) at the chosen
model, 50% breakdown and a minimum distance interpretation.},
  file     = {:lindsay_1994.pdf:PDF},
  keywords = {RAF, residuals adjustment function, weighted likelihood, robustness},
}

@Article{ma_2000,
  author   = {Ma, Y. and Genton, M.G.},
  title    = {Highly Robust Estimation of the Autocovariance FUNCTION},
  journal  = {Journal of Time Series Analysis},
  year     = {2000},
  volume   = {21},
  number   = {6},
  pages    = {663--684},
  abstract = {In this paper, the problem of the robustness of the sample autocovariance
function is addressed. We propose a new autocovariance estimator, based on a highly
robust estimator of scale. Its robustness properties are studied by means of the
in¯uence function, and a new concept of temporal breakdown point. As the theoretical
variance of the estimator does not have a closed form, we perform a simulation study.
Situations with various size of outliers are tested. They con®rm the robustness
properties of the new estimator. An S-Plus function for the highly robust auto-
covariance estimator is made available on the Web at http://www-math.mit.edu/
yanyuan/Genton/Time/time.html. At the end, we analyze a time series of monthly
interest rates of an Austrian bank.},
  file     = {:ma_2000.pdf:PDF},
  keywords = {autocovariance, breakdown point, influence function, robustness, scale estimation},
}

@Article{markatou_1997,
  author   = {Markatou, M. and Basu, A. and Lindsay, B.G.},
  title    = {Weighted Likelihood Estimating Equations: The Discrete Case with Applications to Logistic Regression},
  journal  = {Journal of Statistical Planning and Inference},
  year     = {1997},
  volume   = {57},
  pages    = {215--232},
  abstract = {We discuss a method of weighting the likelihood equations with the aim of obtaining fully
efficient and robust estimators. We discuss the case of discrete probability models using several
weighting functions. If the weight functions generate increasing residual adjustment functions
then the method provides a link between the maximum likelihood score equations and minimum
disparity estimation, as well as a set of diagnostic weights and a goodness of fit criterion.
However, when the weights do not generate increasing residual adjustment functions a selection
criterion is needed to obtain the robust root.
The weight functions discussed in this paper do not automatically downweight a proportion of
the data; an observation is significantly downweighted only if it is inconsistent with the assumed
model. At the true model, therefore, the proposed estimating equations behave like the ordinary
likelihood equations. We apply our results to several discrete models; in addition, a toxicology
experiment illustrates the method in the context of logistic regression.},
  file     = {:markatou_1997.pdf:PDF},
  keywords = {Generalized linear models; Likelihood approach; Residual adjustment functions; Robustness},
}

@Article{markatou_1998,
  author    = {Markatou, M. and Basu, A. and Lindsay, B.G.},
  title     = {Weighted Likelihood Equations with Bootstrap Root Search},
  journal   = {Journal of the American Statistical Association},
  year      = {1998},
  volume    = {93},
  number    = {442},
  pages     = {740--750},
  month     = {jun},
  abstract  = {Wediscuss a method of weighting likelihood equations with the aim of obtaining fully efficient and robust estimators. Wediscuss the
case of continuous probability models using unimodal weighting functions. These weighting functions downweight observations
that are inconsistent with the assumed model. At the true model, therefore, the proposed estimating equations behave like the
ordinary likelihood equations. We investigate the number of solutions of the estimating equations via a bootstrap root search; the
estimators obtained are consistent and asymptotically normal and have desirable robustness properties. An extensive simulation
study and real data examples illustrate the operating characteristics of the proposed methodology.},
  doi       = {10.1080/01621459.1998.10473726},
  file      = {:Markatou_1998.pdf:PDF},
  keywords  = {Asymptotic efficiency; Density estimation; Influence function; Maximum likelihood; Residual adjustment function; Robustness.},
  publisher = {Informa {UK} Limited},
}

@MastersThesis{stapper_2017,
  author   = {Stapper, M.},
  title    = {Robust Fitting of INARCH Processes},
  school   = {TU Dortmund},
  year     = {2017},
  type     = {mathesis},
  month    = may,
  note     = {Not published},
  file     = {:Masterarbeit_Stapper.pdf:PDF},
  keywords = {robust estimation, weighted likelihood, M-estimation, poisson autoregression, minimum density power divergence},
}

@Unpublished{mottonen_1999,
  author   = {Möttönen, J. and Oja, H.},
  title    = {Robust Autocovariance Estimation Based on Sign and Rank Correlation Coefficients},
  year     = {1999},
  abstract = {This paper addresses the problem of estimating autocorrelation
coefficients in the presence of outliers. Tools for
characterizing the robustness are developed as well. Autocorrelation
coefficients are obtained recursively by computing
Partial Correlation (PARCOR) coefficients first. In order
to achieve robustness, product-moment correlation coefficients
are replaced by correlations computed using rank
and sign correlation coefficients. Transformations relating
rank and sign correlations and conventional correlations
are exploited in the process. Finally, robust estimates of
autocorrelation coefficients are obtained. They are used
to construct an autocovariance matrix. Examples of the
performance of the method are given by using a matrix
constructed from autocorrelation coefficients and MUSIC
subspace frequency estimator. The influence of outliers to
conventional estimators and the robustness of the proposed
method are illustrated in simulations as well.},
  file     = {:mottonen_1999.pdf:PDF},
  keywords = {robustness, autocovariance estimation, sign and rank correlation},
}

@Article{park_2002,
  author   = {Park, C. and Basu, A. and Lindsay, B.G.},
  title    = {The residual adjustment function and and weighted likelihood a graphical and interpretation of robustness of and minimum disparity estimators},
  journal  = {Computational Statistics {\&} Data Analysis},
  year     = {2002},
  volume   = {39},
  pages    = {21--33},
  abstract = {The minimum disparity estimators of Lindsay (Ann. Statist. 22 (1994) 1081–1114) combine full
asymptotic e4ciency andattractive robustness properties andhence are useful practical tools. The
residual adjustment function (RAF) introduced and used by Lindsay in this context helps to graphically
interpret the robustness of the estimators, but this representation is not completely satisfactory since the
domain of the RAF is in7nite. In this paper, we develop another graphical representation to summarize
the behavior of the minimum disparity estimators in relation to maximum likelihood which gives useful
insights. c 2002 Elsevier Science B.V. All rights reserved.},
  file     = {:park_2002.pdf:PDF},
  keywords = {Residual adjustment function; Pearson residual; Neyman residual},
}

@Article{paul_basu_2015,
  author    = {Paul, S. and Basu, A.},
  title     = {On second order efficient robust inference},
  journal   = {Computational Statistics {\&} Data Analysis},
  year      = {2015},
  volume    = {88},
  pages     = {187--207},
  month     = aug,
  abstract  = {General strategies for constructing second order efficient robust distances from suitable
properties of the residual adjustment functions (RAF) are discussed. Based on those
properties families of estimators are constructed using the truncated polynomial, negative
exponential and sigmoidal functions as RAFs and their efficiency and robustness properties
are investigated. The estimators have full asymptotic efficiency, and are automatically
second order efficient. Many of the proposed estimators are competitive or better than
the minimum Hellinger distance estimator (MHDE) and minimum negative exponential
disparity estimator (MNEDE) under the combined goals of asymptotic efficiency with
strong robustness properties. Hence the proposed families give the user the flexibility to
choose from a large class of robust second order efficient estimators based upon specific
needs.},
  doi       = {10.1016/j.csda.2015.02.008},
  file      = {:paul_basu_2015.pdf:PDF},
  keywords  = {Hellinger distance Minimum distance inference Negative exponential disparity Residual adjustment function Robustness Second order efficiency},
  publisher = {Elsevier {BV}},
}

@Unpublished{sethuraman_2002,
  author   = {Sethuraman, S.},
  title    = {A Martingale Central Limit Theorem},
  year     = {2002},
  file     = {:sethuraman_2002.pdf:PDF},
  keywords = {martingale central limit theorem},
}

@Article{simpson_1987,
  author   = {Simpson, D.G. and Carroll, R.J. and Ruppert, D.},
  title    = {Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals of Statistics},
  journal  = {The Annaly of Statistics},
  year     = {1987},
  volume   = {15},
  number   = {2},
  pages    = {657--669},
  abstract = {The asymptotic distribution of an M-estimator is studies when the underlying distribution is discrete. Asymptotic normality is shown to hold quite generally within the assumed parametric family. When the specification of the model is inexact, however, it is demonstrated that an M-estimator whose score function is not everywhere differentiable, e.g., a Huber estimator, has a nonnormal limiting distribution at certein distributions, resulting in unstable inference in the neighbourhood of such distributions. Consequently, smooth score functions are proposed for discrete data.},
  file     = {:simpson_1987.pdf:PDF},
  keywords = {M-esitmation, count data, asymptotic distribution},
}

@Article{zhan_2011,
  author    = {Zhan, T. and Chervoneva, I. and Iglewicz, B.},
  title     = {Generalized weighted likelihood density estimators with application to finite mixture of exponential family distributions},
  journal   = {Computational Statistics {\&} Data Analysis},
  year      = {2011},
  volume    = {55},
  number    = {1},
  pages     = {457--465},
  month     = {jan},
  abstract  = {The family of weighted likelihood estimators largely overlaps with minimum divergence
estimators. They are robust to data contaminations compared to MLE. We define the class
of generalized weighted likelihood estimators (GWLE), provide its influence function and
discuss the efficiency requirements. We introduce a new truncated cubic-inverse weight,
which is both first and second order efficient and more robust than previously reported
weights. We also discuss new ways of selecting the smoothing bandwidth and weighted
starting values for the iterative algorithm. The advantage of the truncated cubic-inverse
weight is illustrated in a simulation study of three-component normal mixtures model with
large overlaps and heavy contaminations. A real data example is also provided.},
  doi       = {10.1016/j.csda.2010.05.013},
  file      = {:zhan_2011.pdf:PDF},
  keywords  = {Finite normal mixture Generalized weighted likelihood estimator Influence function Smoothing bandwidth Truncated cubic-inverse weight Weighted starting value},
  publisher = {Elsevier {BV}},
}

@Article{zhu_wang_2011,
  author    = {Zhu, F. and Wang, D.},
  title     = {Estimation and testing for a Poisson autoregressive model},
  journal   = {Metrika},
  year      = {2011},
  volume    = {73},
  number    = {2},
  pages     = {211--230},
  month     = {jul},
  abstract  = {This article considers statistical inference for a Poisson autoregressive
model. A condition for ergodicity and a necessary and sufficient condition for the
existence of moments are given. Asymptotics for maximum likelihood estimator
and weighted least squares estimators with estimated weights or known weights of
the parameters are established. Testing conditional heteroscedasticity and testing the
parameters under a simple ordered restriction are noted. A simulation study is also
given.},
  doi       = {10.1007/s00184-009-0274-z},
  file      = {:zhu_wang.pdf:PDF},
  keywords  = {Asymptotics · Ergodicity · Maximum likelihood estimator · Poisson autoregressive model · Test · Weighted least squares estimator},
  publisher = {Springer Nature},
}

@Book{staudte_1990,
  title     = {Robust Estimation and Testing},
  publisher = {Wiley {\&} Sons},
  year      = {1990},
  author    = {Staudte, R.G. and Sheather, S.J.},
  abstract  = {An introduction to the theory and methods of robust statistics, providing students with practical methods for carrying out robust procedures in a variety of statistical contexts and explaining the advantages of these procedures. In addition, the text develops techniques and concepts likely to be useful in the future analysis of new statistical models and procedures. Emphasizing the concepts of breakdown point and influence functon of an estimator, it demonstrates the technique of expressing an estimator as a descriptive measure from which its influence function can be derived and then used to explore the efficiency and robustness properties of the estimator. Mathematical techniques are complemented by computational algorithms and Minitab macros for finding bootstrap and influence function estimates of standard errors of the estimators, robust confidence intervals, robust regression estimates and their standard errors. Includes examples and problems. },
  doi       = {10.1002/9781118165485},
  file      = {:Staudte_1990\\ch1.pdf:PDF},
  keywords  = {robustness},
}

@Book{maronna_2006,
  title     = {Robust Statistics: Theory and Methods},
  publisher = {Wiley {\&} Sons},
  year      = {2006},
  author    = {Maronna, R.A. and Martin, R.D. and Yohai, V.J.},
  abstract  = {Classical statistical techniques fail to cope well with deviations from a standard distribution. Robust statistical methods take into account these deviations while estimating the parameters of parametric models, thus increasing the accuracy of the inference. Research into robust methods is flourishing, with new methods being developed and different applications considered.

Robust Statistics sets out to explain the use of robust methods and their theoretical justification. It provides an up-to-date overview of the theory and practical application of the robust statistical methods in regression, multivariate analysis, generalized linear models and time series. This unique book:

    Enables the reader to select and use the most appropriate robust method for their particular statistical model.
    Features computational algorithms for the core methods.
    Covers regression methods for data mining applications.
    Includes examples with real data and applications using the S-Plus robust statistics library.
    Describes the theoretical and operational aspects of robust methods separately, so the reader can choose to focus on one or the other.
    Supported by a supplementary website featuring time-limited S-Plus download, along with datasets and S-Plus code to allow the reader to reproduce the examples given in the book. 

Robust Statistics aims to stimulate the use of robust methods as a powerful tool to increase the reliability and accuracy of statistical modelling and data analysis. It is ideal for researchers, practitioners and graduate students of statistics, electrical, chemical and biochemical engineering, and computer vision. There is also much to benefit researchers from other sciences, such as biotechnology, who need to use robust statistical methods in their work. },
  file      = {:maronna_2006\\ch1.pdf:PDF},
  keywords  = {robustness},
}

@Unpublished{Boudreault2011,
  author        = {Boudreault, M. and Charpentier, A.},
  title         = {Multivariate integer-valued autoregressive models applied to earthquake counts},
  year          = {2011},
  __markedentry = {[stapperm:6]},
  abstract      = {In various sit uat ions in t he insurance indust ry, in finance, in epidemiology, et c., one needs t o
represent t he joint evolut ion of t he number of occurrences of an event . In t his paper, we present
a mult ivariat e int eger-valued aut oregressive (MINAR) model, derive it s propert ies and apply t he
model t o eart hquake occurrences across various pairs of t ect onic plat es. T he model is an ext ension
of (Pedeli and K arlis 2011a) where cross aut ocorrelat ion (spat ial cont agion in a seismic cont ext ) is
considered. We fit various bivariat e count models and find t hat for many cont iguous t ect onic plat es,
spat ial cont agion is significant in bot h direct ions. Furt hermore, ignoring cross aut ocorrelat ion can
underest imat e t he pot ent ial for high numbers of occurrences over the short -t erm. Our overall
findings seem t o furt her confirm (Parsons and Velasco 2011).},
  keywords      = {Overview, earthquake counts},
}

@Article{Alzaid1990,
  author        = {Alzaid, A.A. and Al-Osh M.},
  title         = {An Integer-Valued pth-Order Autoregressive Structure (INAR(p)) Process},
  journal       = {Journal of Applied Probability},
  year          = {1990},
  volume        = {27},
  number        = {2},
  pages         = {314--324},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {An extension of the INAR(l) process which is useful for modelling discrete-time dependent counting processes is considered. The model investigated here has a form similar to that of the Gaussian AR(p) process,
and is called the integer-valued pth-order autoregressive structure (INAR(p)) process. Despite the similarity in form, the two processes differ in many aspects such as the behaviour of the correlation,
Markovian property and regression. Among other aspects of the INAR(p) process investigated here are the limiting as well as the joint distributions of the process. 
Also, some detailed discussion is given for the case in which the marginal distribution of the process is Poisson.},
  keywords      = {INAR, pth Order, limiting and joint distribution},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Alzaid1988,
  author        = {Alzaid, A.A. and Al-Osh, M.},
  title         = {First-Order Integer-Valued Autoregressive (INAR(1)) Process: Distributional and Regression Properties},
  journal       = {Statistica Neerlandica},
  year          = {1988},
  volume        = {41},
  number        = {1},
  pages         = {53--60},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {An extension of the INAR(l) process which is useful for modelling discrete-time dependent counting processes is considered. The model investigated here has a form similar to that of the Gaussian AR(p) process,
and is called the integer-valued pth-order autoregressive structure (INAR(p)) process. Despite the similarity in form, the two processes differ in many aspects such as the behaviour of the correlation,
Markovian property and regression. Among other aspects of the INAR(p) process investigated here are the limiting as well as the joint distributions of the process. 
Also, some detailed discussion is given for the case in which the marginal distribution of the process is Poisson.},
  keywords      = {Distribution of INAR(1)},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Boucher2008,
  author        = {Boucher, J.P. and Denuit, M. and Guillén, M.},
  title         = {Models of Insurance Claim Counts with Time Dependence Based on Generalization of Poisson and Negative Binomial Distributions},
  journal       = {Variance: Advancing the Science of Risk},
  year          = {2008},
  volume        = {2},
  number        = {1},
  pages         = {135--162},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Longitudinal data (or panel data) consist of repeated observations
of individual units that are observed over time.
Each individual insured is assumed to be independent but
correlation between contracts of the same individual is
permitted. This paper presents an exhaustive overview of
models for panel data that consist of generalizations of
count distributions where the dependence between contracts
of the same insureds can be modeled with Bayesian
and frequentist models, based on generalization of Poisson
and negative binomial distributions. This paper introduces
some of those models to actuarial science and compares the
fitting with specification tests for nested and non-nested
models. It also shows why some intuitive models (past experience
as regressors, multivariate distributions, or copula
models) involving time dependence cannot be used to
model the number of reported claims. We conclude that
the random effects models have a better fit than the other
models examined here because the fitting is improved and
it allows for more flexibility in computing the next year’s
premium.},
  keywords      = {Insurance, Poisson Process},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Gardner1974,
  author        = {Gardner, J.K. and Knopoff},
  title         = {Is the sequence if earthquakes in southern california, with aftershocks removed, poissonian?},
  journal       = {Bulletin of the Seismological Society of America},
  year          = {1974},
  volume        = {64},
  number        = {5},
  pages         = {1363--1367},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Longitudinal data (or panel data) consist of repeated observations
of individual units that are observed over time.
Each individual insured is assumed to be independent but
correlation between contracts of the same individual is
permitted. This paper presents an exhaustive overview of
models for panel data that consist of generalizations of
count distributions where the dependence between contracts
of the same insureds can be modeled with Bayesian
and frequentist models, based on generalization of Poisson
and negative binomial distributions. This paper introduces
some of those models to actuarial science and compares the
fitting with specification tests for nested and non-nested
models. It also shows why some intuitive models (past experience
as regressors, multivariate distributions, or copula
models) involving time dependence cannot be used to
model the number of reported claims. We conclude that
the random effects models have a better fit than the other
models examined here because the fitting is improved and
it allows for more flexibility in computing the next year’s
premium.},
  keywords      = {Poisson Process, Earthquakes},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Kagan1991,
  author        = {Kagan, Y.Y. and Jackson D.D.},
  title         = {Long-term earthquake clustering},
  journal       = {Geophysical Journal International},
  year          = {1991},
  volume        = {104},
  number        = {5},
  pages         = {117--133},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {We analyse statistically the long-term properties of several instrumental earthquake
catalogues. Complete catalogues exhibit both short- and long-term clustering for
earthquakes of all depth ranges. After accounting for the effect of short-term
clustering, we find that in residual (declustered) catalogues, long-term clustering,
not periodicity, characterizes the occurrence of all earthquakes-shallow, intermediate,
and deep. The degree of clustering in residual catalogues is the same for
earthquakes in different depth ranges. Circumstantial evidence indicates that the
long-term v,ariation of seismicity is governed by a power-law temporal distribution;
as in short-term clustering, it is scale invariant. The fractal dimension of an
earthquake set on the time axis is of the order of 0.8-0.9. Therefore, mainshock
occurrence is closer to a stationary Poisson process than standard aftershock
sequences of shallow earthquakes.},
  keywords      = {Clustering, Earthquake},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Latour1997,
  author        = {Latour, A.},
  title         = {The Multivariate GINAR(p) Process},
  journal       = {Advances in Applied Probability},
  year          = {1997},
  volume        = {29},
  number        = {5},
  pages         = {228--248},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {A criterion is given for the existence of a stationary and causal multivariate integer-valued autoregressive process, MGINAR(p). The autocovariance function of this process being identical to the autocovariance function of a standard Gaussian MAR(p), we deduce that the MGINAR(p) process is nothing but a MAR(p) process. Consequently,, the spectral density is directly found and gives good insight into the stochastic structure of a MGINAR(p). The estimation of parameters of the models as well as the forecasting of the series, is discussed.},
  keywords      = {Multivariate GINAR},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{McKenzie1985,
  author        = {McKenzie, E.},
  title         = {Some Simple Models for Discrete Variate Time Series},
  journal       = {Journal of the American Water Resources Association},
  year          = {1985},
  volume        = {21},
  number        = {4},
  pages         = {645--650},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Simple models are presented for use in the modeling and of higher order chains, but again the problems of large num-
generation of sequences of dependent discrete random variables. The bers of parameters is soon encountered. More recently, the 
models are essentially Markov Chains, but are structurally autoregres- DARMA processes of Jacobs and Lewis (1978a, 1978b) have 
sions, and so depend on only a few parameters. The marginal distribu- 
tion is an intrinsic component: in the specification of each model, and offered an alternative, and have been applied, However, these 
the Poisson, Geometric, Negative Binomial and Binomial distributions processes are extremely general, and derive no benefits from 
are considered. Details are also given for the introduction of time- the structure of particular distributions. Also, dependence is 
dependence into the means of the sequences so that seaonality can be created by means of having runs of specific values. This is un- 
treated simply. likely to be a reasonable assumption, except perhaps in the 
(KEY TERMS: time series; time series analysis; discrete variate time 
series; discrete random variate modeling.) case if Binary variates.},
  keywords      = {Discrete models},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Ogata1988,
  author        = {Ogata, Y.},
  title         = {Statistical Models for Warthquake Occurrences and Residuals Analysis for Point Process},
  journal       = {Journal of the American Statistical Association},
  year          = {1988},
  volume        = {83},
  number        = {401},
  pages         = {9--27},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Simple models are presented for use in the modeling and of higher order chains, but again the problems of large num-
generation of sequences of dependent discrete random variables. The bers of parameters is soon encountered. More recently, the 
models are essentially Markov Chains, but are structurally autoregres- DARMA processes of Jacobs and Lewis (1978a, 1978b) have 
sions, and so depend on only a few parameters. The marginal distribu- 
tion is an intrinsic component: in the specification of each model, and offered an alternative, and have been applied, However, these 
the Poisson, Geometric, Negative Binomial and Binomial distributions processes are extremely general, and derive no benefits from 
are considered. Details are also given for the introduction of time- the structure of particular distributions. Also, dependence is 
dependence into the means of the sequences so that seaonality can be created by means of having runs of specific values. This is un- 
treated simply. likely to be a reasonable assumption, except perhaps in the 
(KEY TERMS: time series; time series analysis; discrete variate time 
series; discrete random variate modeling.) case if Binary variates.},
  keywords      = {Trigger Models, Marked Point Process},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Orfanogiannaki2010,
  author        = {Orfanogiannaki, K. and Karlis, D. and Papadopoulos, G.A.},
  title         = {Identifying Seismicity Levels via Poisson Hidden Markov Models},
  journal       = {Pure and Applied Geophysics},
  year          = {2010},
  volume        = {167},
  number        = {401},
  pages         = {919--931},
  month         = apr,
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Poisson Hidden Markov models (PHMMs) are
introduced to model temporal seismicity changes. In a PHMM the
unobserved sequence of states is a finite-state Markov chain and the
distribution of the observation at any time is Poisson with rate
depending only on the current state of the chain. Thus, PHMMs
allow a region to have varying seismicity rate. We applied the
PHMM to model earthquake frequencies in the seismogenic area of
Killini, Ionian Sea, Greece, between period 1990 and 2006. Simulations
of data from the assumed model showed that it describes
quite well the true data. The earthquake catalogue is dominated by
main shocks occurring in 1993, 1997 and 2002. The time plot of
PHMM seismicity states not only reproduces the three seismicity
clusters but also quantifies the seismicity level and underlies the
degree of strength of the serial dependence of the events at any
point of time. Foreshock activity becomes quite evident before the
three sequences with the gradual transition to states of cascade
seismicity. Traditional analysis, based on the determination of
highly significant changes of seismicity rates, failed to recognize
foreshocks before the 1997 main shock due to the low number of
events preceding that main shock. Then, PHMM has better performance
than traditional analysis since the transition from one
state to another does not only depend on the total number of events
involved but also on the current state of the system. Therefore,
PHMM recognizes significant changes of seismicity soon after they
start, which is of particular importance for real-time recognition of
foreshock activities and other seismicity changes.},
  doi           = {10.1007/s00024-010-0088-y},
  keywords      = {Poisson Hidden Markov Models, seismicity levels, transition probabilities},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Steutel1979,
  author        = {Steutel, F.W. and van Harn, K.},
  title         = {Discrete Analogues of Self-Decomposability and Stability},
  journal       = {The Annals of Probability},
  year          = {1979},
  volume        = {7},
  number        = {5},
  pages         = {893--899},
  month         = apr,
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Poisson Hidden Markov models (PHMMs) are
introduced to model temporal seismicity changes. In a PHMM the
unobserved sequence of states is a finite-state Markov chain and the
distribution of the observation at any time is Poisson with rate
depending only on the current state of the chain. Thus, PHMMs
allow a region to have varying seismicity rate. We applied the
PHMM to model earthquake frequencies in the seismogenic area of
Killini, Ionian Sea, Greece, between period 1990 and 2006. Simulations
of data from the assumed model showed that it describes
quite well the true data. The earthquake catalogue is dominated by
main shocks occurring in 1993, 1997 and 2002. The time plot of
PHMM seismicity states not only reproduces the three seismicity
clusters but also quantifies the seismicity level and underlies the
degree of strength of the serial dependence of the events at any
point of time. Foreshock activity becomes quite evident before the
three sequences with the gradual transition to states of cascade
seismicity. Traditional analysis, based on the determination of
highly significant changes of seismicity rates, failed to recognize
foreshocks before the 1997 main shock due to the low number of
events preceding that main shock. Then, PHMM has better performance
than traditional analysis since the transition from one
state to another does not only depend on the total number of events
involved but also on the current state of the system. Therefore,
PHMM recognizes significant changes of seismicity soon after they
start, which is of particular importance for real-time recognition of
foreshock activities and other seismicity changes.},
  doi           = {10.1007/s00024-010-0088-y},
  keywords      = {Self-Decomposability, discrete time series, Stability},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Utsu1969,
  author        = {Utsu, T.},
  title         = {Aftershocks and Earthquake Statistics(1) : Some Parameters Which Characterize an Aftershock Sequence and Their Interrelations},
  journal       = {Journal of the Faculty of Science, Hokkaido University},
  year          = {1969},
  volume        = {3},
  number        = {3},
  pages         = {129--195},
  month         = apr,
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Poisson Hidden Markov models (PHMMs) are
introduced to model temporal seismicity changes. In a PHMM the
unobserved sequence of states is a finite-state Markov chain and the
distribution of the observation at any time is Poisson with rate
depending only on the current state of the chain. Thus, PHMMs
allow a region to have varying seismicity rate. We applied the
PHMM to model earthquake frequencies in the seismogenic area of
Killini, Ionian Sea, Greece, between period 1990 and 2006. Simulations
of data from the assumed model showed that it describes
quite well the true data. The earthquake catalogue is dominated by
main shocks occurring in 1993, 1997 and 2002. The time plot of
PHMM seismicity states not only reproduces the three seismicity
clusters but also quantifies the seismicity level and underlies the
degree of strength of the serial dependence of the events at any
point of time. Foreshock activity becomes quite evident before the
three sequences with the gradual transition to states of cascade
seismicity. Traditional analysis, based on the determination of
highly significant changes of seismicity rates, failed to recognize
foreshocks before the 1997 main shock due to the low number of
events preceding that main shock. Then, PHMM has better performance
than traditional analysis since the transition from one
state to another does not only depend on the total number of events
involved but also on the current state of the system. Therefore,
PHMM recognizes significant changes of seismicity soon after they
start, which is of particular importance for real-time recognition of
foreshock activities and other seismicity changes.},
  doi           = {10.1007/s00024-010-0088-y},
  keywords      = {Earthquake, Interrelations, Spatial Statistics},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{weiss_2008,
  author        = {Wei{\ss}, C.H.},
  title         = {Thinning operations for modeling time series of counts: a survey},
  journal       = {Advances in Statistical Analysis},
  year          = {2008},
  volume        = {92},
  number        = {3},
  pages         = {319--341},
  month         = may,
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {The analysis of time series of counts is an emerging field of science. To
obtain an ARMA-like autocorrelation structure, many models make use of thinning
operations to adapt the ARMA recursion to the integer-valued case. Most popular
among these probabilistic operations is the concept of binomial thinning, leading to
the class of INARMA models. These models are proved to be useful, especially for
processes of Poisson counts, but may lead to difficulties in the case of different count
distributions. Therefore, several alternative thinning concepts have been developed.
This article reviews such thinning operations and shows how they are successfully
applied to define integer-valued ARMA models.},
  doi           = {10.1007/s10182-008-0072-3},
  keywords      = {Thinning operations · Binomial thinning · Count time series · INAR(1) models},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Jung2006,
  author        = {Robert C Jung and A R Tremayne},
  title         = {Binomial thinning models for integer time series},
  journal       = {Statistical Modelling: An International Journal},
  year          = {2006},
  volume        = {6},
  number        = {2},
  pages         = {81--96},
  month         = {jul},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {This article considers some simple observation-driven time series models for counts.We provide
a brief description of the class of integer-valued autoregressive (INAR) and integer-valued moving average
(INMA) processes. These classes of models may be attractive when the data exhibit a significant serial
dependence structure.We, therefore, briefly reviewvarious testing procedures useful for assessing the serial
correlation in the data. Once it is established that the data are not serially independent, suitable INAR
or INMA processes may be employed to model the data. In the important first order INAR model, we
discuss various methods of estimating the structural parameters of the process.We also give a short account
of the extension of some of these estimation procedures to second order INAR models. Moving average
counterparts of both models are also entertained. Throughout, the models and methods are illustrated in
the context of a famous data set from the branching process literature that turns out to be surprisingly
difficult to model satisfactorily.},
  doi           = {10.1191/1471082x06st114oa},
  keywords      = {Binomial thinning, overview},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Jung2006a,
  author        = {Robert C. Jung and Martin Kukuk and Roman Liesenfeld},
  title         = {Time series of count data: modeling, estimation and diagnostics},
  journal       = {Computational Statistics {\&} Data Analysis},
  year          = {2006},
  volume        = {51},
  number        = {4},
  pages         = {2350--2364},
  month         = {dec},
  issn          = {00219002},
  __markedentry = {[stapperm:6]},
  abstract      = {Various models for time series of counts which can account for discreteness, overdispersion and serial correlation are compared.
Besides observation- and parameter-driven models based upon corresponding conditional Poisson distributions, a dynamic ordered
probit model as a flexible specification to capture the salient features of time series of counts is also considered. For all models,
appropriate efficient estimation procedures are presented. For the parameter-driven specification this requires Monte-Carlo procedures
like simulated maximum likelihood or Markov chain Monte Carlo. The methods, including corresponding diagnostic tests,
are illustrated using data on daily admissions for asthma to a single hospital. Estimation results turn out to be remarkably similar
across the different models.},
  doi           = {10.1016/j.csda.2006.08.001},
  keywords      = {Binomial thinning, overview},
  url           = {http://www.jstor.org/stable/3214650},
}

@Article{Pedeli_2013,
  author    = {Pedeli, X. and Karlis, D.},
  title     = {Some properties of multivariate {INAR}(1) processes},
  journal   = {Computational Statistics {\&} Data Analysis},
  year      = {2013},
  volume    = {67},
  pages     = {213--225},
  month     = {nov},
  abstract  = {INteger-valued AutoRegressive (INAR) processes are common choices for modeling
non-negative discrete valued time series. In this framework and motivated by the frequent
occurrence of multivariate count time series data in several different disciplines, a
generalized specification of the bivariate INAR(1) (BINAR(1)) model is considered. In this
new, full BINAR(1) process, dependence between the two series stems from two sources
simultaneously. The main focus is on the specific parametric case that arises under the
assumption of a bivariate Poisson distribution for the innovations of the process. As it
is shown, such an assumption gives rise to a Hermite BINAR(1) process. The method
of conditional maximum likelihood is suggested for the estimation of its unknown
parameters. A short application on financial count data illustrates the model.},
  doi       = {10.1016/j.csda.2013.05.019},
  file      = {:Pedeli_2013.pdf:PDF},
  keywords  = {Multivariate INAR},
  publisher = {Elsevier {BV}},
}

@Article{Inoue_2013,
  author    = {Inoue, A. and Kilian, L.},
  title     = {Inference on impulse response functions in structural {VAR} models},
  journal   = {Journal of Econometrics},
  year      = {2013},
  volume    = {177},
  number    = {1},
  pages     = {1--13},
  month     = {nov},
  abstract  = {Skepticism toward traditional identifying assumptions based on exclusion restrictions has led to a surge
in the use of structural VAR models in which structural shocks are identified by restricting the sign of
the responses of selected macroeconomic aggregates to these shocks. Researchers commonly report the
vector of pointwise posterior medians of the impulse responses as a measure of central tendency of the
estimated response functions, along with pointwise 68% posterior error bands. It can be shown that this
approach cannot be used to characterize the central tendency of the structural impulse response functions.
We propose an alternative method of summarizing the evidence from sign-identified VAR models
designed to enhance their practical usefulness. Our objective is to characterize the most likely admissible
model(s) within the set of structural VAR models that satisfy the sign restrictions. We show how the set of
most likely structural response functions can be computed from the posterior mode of the joint distribution
of admissible models both in the fully identified and in the partially identified case, and we propose a
highest-posterior density credible set that characterizes the joint uncertainty about this set. Our approach
can also be used to resolve the long-standing problem of how to conduct joint inference on sets of structural
impulse response functions in exactly identified VAR models. We illustrate the differences between
our approach and the traditional approach for the analysis of the effects of monetary policy shocks and of
the effects of oil demand and oil supply shocks.},
  doi       = {10.1016/j.jeconom.2013.02.009},
  file      = {:_Inoue, Kilian (2013) - Inference on impulse response functions in structural VAR models.pdf:PDF},
  keywords  = {Vector autoregression Simultaneous inference Impulse responses Sign restrictions Median Mode Credible set},
  publisher = {Elsevier {BV}},
}

@Article{Fry_2011,
  author    = {Fry, R. and Pagan, A.},
  title     = {Sign Restrictions in Structural Vector Autoregressions: A Critical Review},
  journal   = {Journal of Economic Literature},
  year      = {2011},
  volume    = {49},
  number    = {4},
  pages     = {938--960},
  month     = {dec},
  abstract  = {The paper provides a review of the estimation of structural vector autoregressions
with sign restrictions. It is shown how sign restrictions solve the parametric identification
problem present in structural systems but leaves the model identification
problem unresolved. A market and a macro model are used to illustrate these points.
Suggestions have been made on how to find a unique model. These are reviewed. An
analysis is provided of whether one can recover the true impulse responses and what
difficulties might arise when one wishes to use the impulse responses found with sign
restrictions.},
  doi       = {10.1257/jel.49.4.938},
  file      = {:_Fry, Pagan (2011) - Sign Restrictions in Structural Vector Autoregressions - A Critical Review.pdf:PDF},
  keywords  = {SVAR, Sign Restriction},
  publisher = {American Economic Association},
}

@Unpublished{Brandt_2011,
  author   = {Brandt, P.},
  title    = {A Bayesian Poisson Vector Autoregression Model},
  year     = {2011},
  abstract = {Multivariate count models are rare in political science, despite the presence of many
count time series. This article develops a new Bayesian Poisson vector autoregression
(BaP-VAR) model that can characterize endogenous dynamic counts with no restric-
tions on the contemporaneous correlations. Impulse responses, decomposition of the
forecast errors, and dynamic multiplier methods for the effects of exogenous covariate
shocks are illustrated for the model. Two full illustrations of the model, its interpreta-
tions, and results are presented. The first example is a dynamic model that reanalyzes
the patterns and predictors of superpower rivalry events. The second example ap-
plies the model to analyze the dynamics of transnational terrorist targeting decisions
between 1968 and 2008. The latter example’s results have direct implications for con-
temporary policy about terrorists’ targeting that are both novel and innovative in the
study of terrorism.},
  file     = {:_BaPVAR-20111230.pdf:PDF},
  keywords = {Poisson Autoregression Bayes Estimation VAR Count Data},
}

@Article{tayefi_2012,
  author   = {Maryam Tayefi and T.V. Ramanathan},
  title    = {An Overview of FIGARCH and Related Time Series Models},
  journal  = {Australian Journal of Statistics},
  year     = {2012},
  volume   = {41},
  number   = {3},
  pages    = {175-196},
  abstract = {This paper reviews the theory and applications related to fractionally integrated generalized autoregressive conditional heteroscedastic (FIGARCH) models, mainly for describing the observed persistence in the volatility of a time series. The long memory nature of FIGARCH models allows to be a better candidate than other conditional heteroscedastic models for modeling volatility in exchange rates, option prices, stock market returns and inflation rates. We discuss some of the important properties of FIGARCH models in
this review. We also compare the FIGARCH with the autoregressive fractionally integrated moving average (ARFIMA) model. Problems related to parameter estimation and forecasting using a FIGARCH model are presented. The application of a FIGARCH model to exchange rate data is discussed. We briefly introduce some other models, that are closely related to FIGARCH models. The paper ends with some concluding remarks and future directions of research.},
  doi      = {10.17713/ajs.v41i3.172},
  file     = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\tayefi_2012.pdf:PDF},
  keywords = {FIGARCH},
  url      = {https://doi.org/10.17713/ajs.v41i3.172 },
}

@Article{conrad_2010,
  author   = {Conrad, Christian},
  title    = {Non-negativity conditions for the hyperbolic GARCH model},
  journal  = {Journal of Econometrics},
  year     = {2010},
  volume   = {157},
  number   = {2},
  pages    = {441-457},
  abstract = {In this article we derive conditions which ensure the non-negativity of the conditional variance in the Hyperbolic GARCH(p,d,q) (HYGARCH) model of Davidson (2004). The conditions are necessary and sufficient for p=1 and sufficient for p&gt;=2 and emerge as natural extensions of the inequality constraints derived in Nelson and Cao (1992) and Tsai and Chan (2008) for the GARCH model and in Conrad and Haag (2006) for the FIGARCH model. As a by-product we obtain a representation of the ARCH([infinity]) coefficients which allows computationally efficient multi-step-ahead forecasting of the conditional variance of a HYGARCH process. We also relate the necessary and sufficient parameter set of the HYGARCH to the necessary and sufficient parameter sets of its GARCH and FIGARCH components. Finally, we analyze the effects of erroneously fitting a FIGARCH model to a data sample which was truly generated by a HYGARCH process. Empirical applications of the HYGARCH(1,d,1) model to daily NYSE and DAX30 data illustrate the importance of our results.},
  keywords = {Inequality constraints Fractional integration Long memory GARCH processes},
  url      = {https://EconPapers.repec.org/RePEc:eee:econom:v:157:y:2010:i:2:p:441-457},
}

@Article{smith_1938,
  author  = {Smith, H.},
  title   = {An empirical law describing heterogeneity in the yields of agricultural crops},
  journal = {The Journal of Agricultural Science},
  year    = {1938},
  volume  = {28},
  pages   = {1-23},
  doi     = {10.1017/S0021859600050516},
  url     = {https://doi.org/10.1017/S0021859600050516},
}

@Article{cox_1947,
  author  = {Cox, D.R. and Townsend, M.W.H.},
  title   = {The Use of the Correlogram in Measuring Yarm Irregularity},
  journal = {Proc. Int. Wool Textile Organization, Technical Committee 2},
  year    = {1947},
  pages   = {28-34},
}

@Book{hurst_1951,
  title     = {Long-term Storage Capacity of Reservoirs},
  publisher = {American Society of Civil Engineers},
  year      = {1951},
  author    = {Hurst, H.E.},
  url       = {https://books.google.de/books?id=aKj4HAAACAAJ},
}

@Article{mandelbrot_1963,
  author  = {Mandelbrot, B.},
  title   = {The Variation of Certain Speculative Prices},
  journal = {The Journal of Business},
  year    = {1963},
  volume  = {36},
  number  = {4},
  pages   = {394 - 419},
  url     = {http://www.jstor.org/stable/2350970},
}

@Article{ding_granger_1996,
  author   = {Ding, Z. and Granger, C.W.J.},
  title    = {Modeling Volatility Persistence of Speculative Returns: A New Approach},
  journal  = {Journal of Econometrics},
  year     = {1996},
  volume   = {73},
  pages    = {185-215},
  abstract = {This paper extends the work by Ding, Granger, and Engle (1993) and further examines the long memory property for various speculative returns. The long memory property found for S&P 500 returns is also found to exist for four other different speculative returns. One significant difference is that for foreign exchange rate returns, this property is strongest when instead of at d = 1 for stock returns. The theoretical autocorrelation functions for various GARCH(1, 1) models are also derived and found to be exponential decreasing, which is rather different from the sample autocorrelation function for the real data. A general class of long memory models that has no memory in returns themselves but long memory in absolute returns and their power transformations is proposed. The issue of estimation and simulation for this class of model is discussed. The Monte Carlo simulation shows that the theoretical model can mimic the stylized empirical facts strikingly well.},
  doi      = {10.1016/0304-4076(95)01737-2},
  file     = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\ding_granger_1996.pdf:PDF},
  url      = {https://doi.org/10.1016/0304-4076(95)01737-2},
}

@Article{granger_1980,
  author  = {Granger, C.W.J.},
  title   = {Long Memory Relationships and the Aggregation of Dynamix Models},
  journal = {Journal of Econometrics},
  year    = {1980},
  volume  = {14},
  pages   = {227 - 238},
  doi     = {10.1016/0304-4076(80)90092-5},
  file    = {:granger_1980.pdf:PDF},
  url     = {https://doi.org/10.1016/0304-4076(80)90092-5},
}

@Article{Granger_1980,
  author    = {C. W. J. Granger and Roselyne Joyeux},
  title     = {{AN} {INTRODUCTION} {TO} {LONG}-{MEMORY} {TIME} {SERIES} {MODELS} {AND} {FRACTIONAL} {DIFFERENCING}},
  journal   = {Journal of Time Series Analysis},
  year      = {1980},
  volume    = {1},
  number    = {1},
  pages     = {15--29},
  month     = {jan},
  doi       = {10.1111/j.1467-9892.1980.tb00297.x},
  publisher = {Wiley},
}

@Article{granger_1981,
  author  = {Granger, C.W.J.},
  title   = {Some properties of time series data and their use in econometric model specification},
  journal = {Journal of Econometrics},
  year    = {1981},
  volume  = {16},
  number  = {1},
  pages   = {121 - 130},
  doi     = {10.1016/0304-4076(81)90079-8},
  file    = {:granger_1981.pdf:PDF},
  url     = {https://doi.org/10.1016/0304-4076(81)90079-8},
}

@Article{hosking_1981,
  author  = {Hosking, J.R.M.},
  title   = {Fractional Differencing},
  journal = {Biometrics},
  year    = {1981},
  volume  = {68},
  number  = {1},
  pages   = {165 - 176},
  month   = apr,
  doi     = {10.1093/biomet/68.1.165},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\hosking_1981.pdf:PDF},
  url     = {https://doi.org/10.1093/biomet/68.1.165},
}

@Article{quoreshi_2014,
  author   = {Quoreshi, A.M.M.S.},
  title    = {A Long-Memory Integer-Valued Time Series Model, INARFIMA, for Financial Application},
  journal  = {Quantitative Finance},
  year     = {2014},
  volume   = {14},
  number   = {12},
  pages    = {2225 - 2235},
  issn     = {1469-7688},
  abstract = {A model to account for the long-memory property in a count data framework is proposed and
applied to high-frequency stock transactions data. By combining features of the INARMA
and ARFIMA models, an Integer-valued Auto Regressive Fractionally Integrated Moving
Average (INARFIMA) model is proposed. The unconditional and conditional first- and
second-order moments are given. The CLS, FGLS and GMM estimators are discussed. In its
empirical application to two stock series for AstraZeneca and Ericsson B, we find that both
series have a fractional integration property.},
  doi      = {10.1080/14697688.2012.711911},
  file     = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\Quoreshi_2014.pdf:PDF},
  url      = {https://doi.org/10.1080/14697688.2012.711911},
}

@Article{conrad_2006,
  author  = {Conrad, C. and Haag, B.R.},
  title   = {Inequality Constraints in the Fractionally Integrated GARCH Model},
  journal = {Journal of Financial Econometrics},
  year    = {2006},
  volume  = {4},
  number  = {3},
  pages   = {413 - 449},
  month   = jul,
  doi     = {10.1093/jjfinec/nbj015},
  file    = {:conrad_2006.pdf:PDF},
  url     = {https://doi.org/10.1093/jjfinec/nbj015},
}

@Article{bougerol_1992,
  author  = {Bougerol, P. and Picard, N.},
  title   = {Stationarity of Garch processes and of some nonnegative time series},
  journal = {Journal of Econometrics},
  year    = {1992},
  volume  = {52},
  number  = {1-2},
  pages   = {115 - 127},
  month   = apr,
  doi     = {10.1016/0304-4076(92)90067-2},
  file    = {:bougerol_1992.pdf:PDF},
  url     = {https://doi.org/10.1016/0304-4076(92)90067-2},
}

@PhdThesis{braccini_2015,
  author = {Braccini, L.},
  title  = {Essays in Dynamic Duration and Count Modelling},
  school = {University of Pennsylvania},
  year   = {2015},
  file   = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\braccini_2015.pdf:PDF},
}

@Article{conrad_karanasos_2006,
  author   = {Christian Conrad and Menelaos Karanasos},
  title    = {The impulse response function of the long memory GARCH process},
  journal  = {Economics Letters},
  year     = {2006},
  volume   = {90},
  number   = {1},
  pages    = {34 - 41},
  issn     = {0165-1765},
  doi      = {https://doi.org/10.1016/j.econlet.2005.07.001},
  keywords = {Cumulative impulse response function, Long memory GARCH process},
  url      = {http://www.sciencedirect.com/science/article/pii/S016517650500251X},
}

@Article{calvet_2001,
  author  = {Calvet, L. and Fisher, A.},
  title   = {Forecasting Multifractal Volatility},
  journal = {Journal of Econometrics},
  year    = {2001},
  volume  = {105},
  number  = {1},
  pages   = {27 - 58},
  doi     = {10.1016/S0304-4076(01)00069-0},
  file    = {:calvet_2001.pdf:PDF},
  url     = {http://dx.doi.org/10.1016/S0304-4076(01)00069-0},
}

@Article{daley_2000,
  author  = {Daley, D.J. and Rolski, T. and Vesilo, R.},
  title   = {Long-Range Dependent Point Processes and their Palm-Khinchin Distributions},
  journal = {Advances in Applied Probability},
  year    = {2000},
  volume  = {32},
  number  = {4},
  pages   = {1051 - 1063},
  month   = dec,
  issn    = {0001-8678},
  doi     = {10.1239/aap/1013540347},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\daley_2000.pdf:PDF},
  url     = {http://www.jstor.org/stable/1428516},
}

@Unpublished{cox_2014,
  author = {Cox, D.},
  title  = {Scaling},
  note   = {Symposium Presentation and Video, Nufflield College Oxford},
  year   = {2014},
  url    = {https://vimeo.com/102835403},
}

@Article{Liboschik_2017,
  author    = {Tobias Liboschik and Konstantinos Fokianos and Roland Fried},
  title     = {tscount: An R Package for Analysis of Count Time Series Following Generalized Linear Models},
  journal   = {Journal of Statistical Software},
  year      = {2017},
  volume    = {82},
  number    = {5},
  doi       = {10.18637/jss.v082.i05},
  publisher = {Foundation for Open Access Statistic},
}

@Manual{tscount_package_2017,
  title  = {tscount: Analysis of Count Time Series},
  author = {Liboschik, T. and Fried, R. and Fokianos, K. and Probst, P.},
  year   = {2017},
  isbn   = {1},
  note   = {R package version 1.4.1},
  url    = {https://CRAN.R-project.org/package=tscount},
}

@Manual{R_2018,
  title        = {R: A Language and Environment for Statistical Computing},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  edition      = {3.4.4},
  month        = mar,
  year         = {2018},
  url          = {https://www.R-project.org},
}

@Article{bollerslev_1996,
  author  = {Bollerslev, T. and Mikkelsen, H.O.},
  title   = {Modeling and Pricing Long Memory in Stock Market Volatility},
  journal = {Journal of Econometrics},
  year    = {1996},
  volume  = {73},
  number  = {1},
  pages   = {151 - 184},
  issn    = {0304-4076},
  doi     = {10.1016/0304-4076(95)01736-4},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\bollerslev_1996.pdf:PDF},
  url     = {https://doi.org/10.1016/0304-4076(95)01736-4},
}

@Article{baillie_1996,
  author   = {Baillie, R. T.},
  title    = {Long Memory Processes and Fractional Integration in Economics},
  journal  = {Journal of Econometrics},
  year     = {1996},
  volume   = {73},
  number   = {1},
  pages    = {5 - 58},
  month    = jul,
  abstract = {This paper provides a survey and review of the major econometric work on long
memory processes, fractional integration, and their applications in economics and
finance. Some of the definitions of long memory are reviewed, together with previous
work in other disciplines. Section 3 describes the population characteristics of various
long memory processes in the mean, including ARFIMA. Section 4 is concerned with
estimation and examines semiparametric procedures in both *he frequency and time
domain, and also the properties of various regression based and maximum likelihood
techniques. Long memory volatility processes are discussed in Section 5, while Section
6 discusses applications in economics and finance. The paper also has a concluding
section.},
  doi      = {10.1016/j.jeconom.2008.09.034.},
  file     = {:Baillie_1996.pdf:PDF},
  keywords = {Fractional Integration, Long Memory Processes, Hurst Effect, ARFIMA, FIGARCH, Stochastic Volatility},
  url      = {http://www.sciencedirect.com/science/article/pii/S0304407608001243},
}

@Article{davidson_2004,
  author    = {Davidson, J.},
  title     = {Moment and Memory Properties of Linear Conditional Heteroscedasticity Models, and a New Model},
  journal   = {Journal of Business \& Economic Statistics},
  year      = {2004},
  volume    = {22},
  number    = {1},
  pages     = {16-29},
  abstract  = { This article analyses the statistical properties of that general class of conditional heteroscedasticity models in which the conditional variance is a linear function of squared lags of the process. GARCH, IGARCH, FIGARCH, and a newly proposed generalization, the HYGARCH model, belong to this class. Conditions are derived for the existence of second and fourth moments, and for the limited memory condition of near-epoch dependence. The HYGARCH model is applied to 10 daily dollar exchange rates, and also to data for Asian exchange rates over the 1997 crisis period. In the latter case, the model exhibits notable stability across the pre-crisis and post-crisis periods. },
  doi       = {10.1198/073500103288619359},
  eprint    = {https://doi.org/10.1198/073500103288619359},
  publisher = {Taylor \& Francis},
  url       = { 
        https://doi.org/10.1198/073500103288619359
    
},
}

@Article{engle_1986,
  author    = {Engle, R. F. and Bollerslev, T.},
  title     = {Modeling the Persistence of Conditional Variances},
  journal   = {Econometric Reviews},
  year      = {1986},
  volume    = {5},
  number    = {1},
  pages     = {1-50},
  month     = {02},
  booktitle = {Econometric Reviews},
}

@Article{hainaut_2014,
  author   = {Hainaut, D. and Boucher, J.-P.},
  title    = {Frequency and Severity Modelling Using Multifractal Processes: An Application to Tornado Occurrence in the USA and CAT Bonds},
  journal  = {Environmental Modeling {\&} Assessment},
  year     = {2014},
  volume   = {19},
  number   = {3},
  pages    = {207--220},
  month    = {Jun},
  issn     = {1573-2967},
  abstract = {This paper proposes a statistical model for insurance claims arising from climatic events, such as tornadoes in the USA, that exhibit a large variability both in frequency and intensity. To represent this variability and seasonality, the claims process modelled by a Poisson process of intensity equal to the product of a periodic function, and a multifractal process is proposed. The size of claims is modelled in a similar way, with gamma random variables. This method is shown to enable simulation of the peak times of damage. A two-dimensional multifractal model is also investigated. The work concludes with an analysis of the impact of the model on the yield of weather bonds linked to damage caused by tornadoes.},
  day      = {01},
  doi      = {10.1007/s10666-013-9388-9},
  file     = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\Hainaut_Boucher_2014.pdf:PDF},
  url      = {https://doi.org/10.1007/s10666-013-9388-9},
}

@Article{haldrup_2017,
  author   = {Haldrup, N. and Valdes, J. E. V.},
  title    = {Long memory, fractional integration, and cross-sectional aggregation},
  journal  = {Journal of Econometrics},
  year     = {2017},
  volume   = {199},
  number   = {1},
  pages    = {1 - 11},
  issn     = {0304-4076},
  doi      = {https://doi.org/10.1016/j.jeconom.2017.03.001},
  file     = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\haldrup_2017.pdf:PDF},
  keywords = {Long memory, Fractional integration, Aggregation},
  url      = {http://www.sciencedirect.com/science/article/pii/S0304407617300428},
}

@TechReport{heinen_2003,
  author      = {Heinen, A.},
  title       = {Modelling Time Series Count Data: An Autoregressive Conditional Poisson Model},
  institution = {University Library of Munich, Germany},
  year        = {2003},
  type        = {MPRA Paper},
  abstract    = {This paper introduces and evaluates new models for time series count data. The Autoregressive Conditional Poisson model (ACP) makes it possible to deal with issues of discreteness, overdispersion (variance greater than the mean) and serial correlation. A fully parametric approach is taken and a marginal distribution for the counts is specified, where conditional on past observations the mean is autoregressive. This enables to attain improved inference on coefficients of exogenous regressors relative to static Poisson regression, which is the main concern of the existing literature, while modelling the serial correlation in a flexible way. A variety of models, based on the double Poisson distribution of Efron (1986) is introduced, which in a first step introduce an additional dispersion parameter and in a second step make this dispersion parameter time-varying. All models are estimated using maximum likelihood which makes the usual tests available. In this framework autocorrelation can be tested with a straightforward likelihood ratio test, whose simplicity is in sharp contrast with test procedures in the latent variable time series count model of Zeger (1988). The models are applied to the time series of monthly polio cases in the U.S between 1970 and 1983 as well as to the daily number of price change durations of :75$ on the IBM stock. A .75$ price change duration is defined as the time it takes the stock price to move by at least .75$. The variable of interest is the daily number of such durations, which is a measure of intradaily volatility, since the more volatile the stock price is within a day, the larger the counts will be. The ACP models provide good density forecasts of this measure of volatility.},
  keywords    = {Forecast; volatility; transactions data},
  url         = {https://EconPapers.repec.org/RePEc:pra:mprapa:8113},
}

@Article{deo_2009,
  author    = {Hurvich, C. M. and Deo, R. and Soulier, P. and Wang, Y.},
  title     = {Conditions for the Propagation of Memory Parameter from Durations to Counts and Realized Volatility},
  year      = {2009},
  volume    = {25},
  pages     = {764-792},
  month     = {06},
  booktitle = {Econometric Theory},
}

@Article{bollerslev_1986,
  author  = {Bollerslev, T.},
  title   = {Generalized Autoregressive Conditional Heteroscedasticity},
  journal = {Journal of Econometrics},
  year    = {1986},
  volume  = {31},
  pages   = {307 - 327},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\Arbeit\\Paper\\bollerslev_1986.pdf:PDF},
}

@Article{zaffaroni_2004,
  author   = {Zaffaroni, P.},
  title    = {Stationarity and Memory of ARMA($\infty$) Models},
  journal  = {Econometric Theory},
  year     = {2004},
  volume   = {20},
  number   = {1},
  pages    = {147 - 160},
  month    = feb,
  abstract = {We establish the necessary and sufficient conditions for covariance stationarity of ARCH(oo), for both the levels and the squares. The result applies to any form of the conditional variance coefficients. This includes GARCH(p, q) and also speci- fications with hyperbolically decaying coefficients, such as the autoregressive co- efficients of the autoregressive fractionally integrated moving average model. The covariance stationarity condition for the levels rules out long memory in the squares.},
  doi      = {10.1017/S0266466604201062},
  file     = {:Zaffaroni_2004.pdf:PDF},
  url      = {https://www.jstor.org/stable/3533507},
}

@Article{zaffaroni_2000,
  author  = {Zaffaroni, P.},
  title   = {Stationarity and Memory of ARCH Models},
  journal = {Discussion Paper},
  year    = {2000},
  file    = {:Zaffaroni_2000.pdf:PDF},
  url     = {http://eprints.lse.ac.uk/6867/},
}

@Article{brownlees_2006,
  author  = {Brownlees, C.T. and Gallo, G.M.},
  title   = {Financial econometric analysis of ultra-high frequency: Data handling concerns},
  journal = {Computational Statistics {\&} Data Analysis},
  year    = {2006},
  volume  = {51},
  pages   = {2232 - 2245},
  doi     = {10.1016/j.csda.2006.09.030},
  file    = {:new\\Brownlees_2006.pdf:PDF},
  url     = {https://doi.org/10.1016/j.csda.2006.09.030},
}

@Article{maronna_2002,
  author  = {Maronna, R. and Zamar, R.},
  title   = {Robust Estimates of Location and Dispersion for High-Dimensional Datasets},
  journal = {Technometrics},
  year    = {2002},
  volume  = {44},
  number  = {4},
  pages   = {307-317},
  doi     = {10.1198/004017002188618509},
  file    = {:maronna_zamar_2002.pdf:PDF},
  url     = {https://doi.org/10.1198/004017002188618509},
}

@Article{czado_2009,
  author  = {Czado, C. and Gneiting, T. and Held, L.},
  title   = {Predictive Model Assessment for Count Data},
  journal = {Biometrics},
  year    = {2009},
  volume  = {65},
  number  = {4},
  pages   = {1254-1261},
  month   = dec,
  doi     = {10.1111/j.1541-0420.2009.01191.x},
  file    = {:czado_2007.pdf:PDF},
  url     = {https://doi.org/10.1111/j.1541-0420.2009.01191.x},
}

@Article{ding_1993,
  author  = {Ding, Z. and Granger, C.W.J. and Engle, R.F.},
  title   = {A Long Memory Property of Stock market Returns and a new Model},
  journal = {Journal of Empirical Finance},
  year    = {1993},
  volume  = {1},
  pages   = {83 - 106},
  file    = {:ding_1993.pdf:PDF},
}

@Article{sibbertsen_2004,
  author   = {Sibbertsen, Philipp},
  title    = {Long memory versus structural breaks: An overview},
  journal  = {Statistical Papers},
  year     = {2004},
  volume   = {45},
  number   = {4},
  pages    = {465--515},
  month    = {Oct},
  issn     = {1613-9798},
  abstract = {We discuss the increasing literature on misspecifying structural breaks or more general trends as long-range dependence. We consider tests on structural breaks in the long-memory regression model as well as the behaviour of estimators of the memory parameter when structural breaks or trends are in the data but long memory is not. Methods for distinguishing both of these phenomena are proposed.},
  day      = {01},
  doi      = {10.1007/BF02760564},
  url      = {https://doi.org/10.1007/BF02760564},
}

@Article{fokianos_2014,
  author   = {Christou, V. and Fokianos, K.},
  title    = {Quasi-Likelihood Inference for Negative Binomial Time Series Models},
  journal  = {Journal of Time Series Analysis},
  year     = {2014},
  volume   = {35},
  number   = {1},
  pages    = {55-78},
  abstract = {We study inference and diagnostics for count time series regression models that include a feedback mechanism. In particular, we are interested in negative binomial processes for count time series. We study probabilistic properties and quasi-likelihood estimation for this class of processes. We show that the resulting estimators are consistent and asymptotically normally distributed. These facts enable us to construct probability integral transformation plots for assessing any assumed distributional assumptions. The key observation in developing the theory is a mean parameterized form of the negative binomial distribution. For transactions data, it is seen that the negative binomial distribution offers a better fit than the Poisson distribution. This is an immediate consequence of the fact that transactions can be represented as a collection of individual activities that correspond to different trading strategies.},
  doi      = {10.1111/jtsa.12050},
  file     = {:C\:\\Users\\stapperm\\sciebo\\Arbeit\\Paper\\christou_2014.pdf:PDF},
  url      = {https://doi.org/10.1111/jtsa.12050},
}

@Article{wang_2012,
  author   = {Wang, X. and Kockelman, K. and Lemp, J.},
  title    = {The dynamic spatial multinomial probit model: analysis of land use change using parcel-level Data},
  journal  = {Journal of Transport Geography},
  year     = {2012},
  volume   = {24},
  pages    = {77-88},
  abstract = {Many transportation-related behaviors involve multinomial discrete response in a temporal and spatial
context. These include quality of paved roadway sections over time, evolution of land use at the parcel
level, vehicle purchases by socially networked households, and mode choices by individuals residing
across adjacent homes or neighborhoods. Such responses depend on various influential factors, and
can have temporal and spatial dependence or autocorrelation. In many cases, dynamic spatial-model
specifications based on maximum fitness, profit or utility may be most appropriate.
This study develops a dynamic spatial multinomial probit (DSMNP) model by pivoting off the ordinary
MNP model while incorporating spatial and temporal dependencies. The study adds value to existing
work by addressing polytomous outcomes and space–time data. (Most spatial models rely on
cross-sectional data sets and/or binary outcomes.) The paper first explains how the model reflects behaviors
at play, and then describes estimation using Bayesian methods, which are of great interest in multiple
fields. Simulated data sets containing both generic and alternative-specific explanatory variables are
used to validate the model’s performance (and that of its associated code). Estimation efficiency issues
and identification issues are discussed. The model is then applied to analyze parcel-level land use
changes in Austin, Texas. It is found that better accessibility boosts the potential of residential development
while hampering non-residential development. The effects of job and population density, neighborhood
income and soil slope are also explored, and found to exert variable effects across space. It is also
found that land development tends to cluster when existing development intensity in a neighborhood
is low.},
  doi      = {10.1016/j.jtrangeo.2012.06.011},
  file     = {:wang_2012.pdf:PDF},
  url      = {http://dx.doi.org/10.1016/j.jtrangeo.2012.06.011},
}

@Article{wang_2013,
  author   = {Wang, Y. and Kockelman, K.},
  title    = {A Poisson-lognormal conditional-autoregressive model for multivariate spatial analysis of pedestrian crash counts across meighbourhoods},
  journal  = {Accident Analysis and Prevention},
  year     = {2013},
  volume   = {60},
  pages    = {71-84},
  abstract = {This work examines the relationship between 3-year pedestrian crash counts across Census tracts in
Austin, Texas, and various land use, network, and demographic attributes, such as land use balance,
residents’ access to commercial land uses, sidewalk density, lane-mile densities (by roadway class),
and population and employment densities (by type). The model specification allows for region-specific
heterogeneity, correlation across response types, and spatial autocorrelation via a Poisson-based multivariate
conditional auto-regressive (CAR) framework and is estimated using Bayesian Markov chain
Monte Carlo methods. Least-squares regression estimates of walk-miles traveled per zone serve as the
exposure measure. Here, the Poisson-lognormal multivariate CAR model outperforms an aspatial Poissonlognormal
multivariate model and a spatial model (without cross-severity correlation), both in terms of
fit and inference.
Positive spatial autocorrelation emerges across neighborhoods, as expected (due to latent heterogeneity
or missing variables that trend in space, resulting in spatial clustering of crash counts). In comparison,
the positive aspatial, bivariate cross correlation of severe (fatal or incapacitating) and non-severe crash
rates reflects latent covariates that have impacts across severity levels but are more local in nature (such
as lighting conditions and local sight obstructions), along with spatially lagged cross correlation. Results
also suggest greater mixing of residences and commercial land uses is associated with higher pedestrian
crash risk across different severity levels, ceteris paribus, presumably since such access produces more
potential conflicts between pedestrian and vehicle movements. Interestingly, network densities show
variable effects, and sidewalk provision is associated with lower severe-crash rates.},
  doi      = {10.1016/j.aap.2013.07.030},
  file     = {:wang_2013.pdf:PDF},
  url      = {http://dx.doi.org/10.1016/j.aap.2013.07.030},
}

@Article{heinen_2003b,
  author = {Heinen, A. and Rengifo, E.},
  title  = {Multivariate Modelling of Time Series Count Data: An Autoregressive Conditional Poisson Model},
  year   = {2003},
  file   = {:heinen_2003b.pdf:PDF},
}

@Article{heinen_2007,
  author  = {Heinen, A. and Rengifo, E.},
  title   = {Multivariate autoregressive modeling of time series count data using copulas},
  journal = {Journal of Empirical Finance},
  year    = {2007},
  volume  = {14},
  pages   = {564-583},
  doi     = {10.1016/j.jempfin.2006.07.004},
  file    = {:heinen_2007.pdf:PDF},
  url     = {https://doi.org/10.1016/j.jempfin.2006.07.004},
}

@Article{h,
  author = {Heinen, A. and Valgesogo, A.},
  title  = {Asymmetric CAPM dependence for large dimensions: the Canonical Vine Autoregressive Model},
  year   = {2009},
  file   = {:heinen_2009.pdf:PDF},
}

@Misc{Bloomberg_2019,
  author = {Bloomberg L.P.},
  note   = {Retrieved from Bloomberg database via R API},
}

@Misc{Bloomberg2019,
  author = {Bloomberg, L.P.},
  year   = {2019},
  note   = {Bloomberg L.P., Retrieved from Bloomberg database via R API},
}

@Article{,
  author = {Spierdijl, L. and Nijman, T. E. and Van Soest, A.},
  title  = {Modeling Comovements in Trading Intensitiesto Distinguish Sector and Stock Specific News},
  file   = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\spierdijk_2002.pdf:PDF},
}

@InProceedings{spierdijk_2002,
  author = {Spierdijk, L. and Nijman, T. and Van Soest, A.},
  title  = {Modeling Comovements in Trading Intensitiesto Distinguish Sector and Stock Specific News},
  year   = {2002},
  file   = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\spierdijk_2002.pdf:PDF},
}

@Unpublished{Spierdijk2002,
  author = {Spierdijk, L. and Nijman, T. and Van Soest, A.},
  title  = {Modeling Comovements in Trading Intensitiesto Distinguish Sector and Stock Specific News},
  note   = {CentER Discussion Paper No. 2002-69, Tilburg University},
  year   = {2002},
  file   = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\spierdijk_2002.pdf:PDF},
}

@Article{Heinen2007,
  author  = {Heinen, A. and Rengifo, E.},
  title   = {Multivariate Autoregressive Modeling of Time Series Count Data Using copulas},
  journal = {Journal of Empirical Finance},
  year    = {2007},
  volume  = {14},
  pages   = {564-583},
  doi     = {10.1016/j.jempfin.2006.07.004},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\heinen_2007.pdf:PDF},
  url     = {https://doi.org/10.1016/j.jempfin.2006.07.004},
}

@Book{winkelmann_2008,
  title     = {Econometric Analysis of Count Data},
  publisher = {Springer},
  year      = {2008},
  author    = {Winkelmann, R.},
  doi       = {10.1007/978-3-540-78389-3},
  file      = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\Winkelmann - Econometric Analysis of Count Data\\[Rainer_Winkelmann]_Econometric_Analysis_of_Count_Data.pdf:PDF},
  url       = {https://www.springer.com/de/book/9783540776482},
}

@Article{jorgensen_1999,
  author  = {Jorgensen, B. and Lundbye-Christensen, S. and Song, P. and Sun, L.},
  title   = {A State Space Model for Multivariate Longitudinal Count Data},
  journal = {Biometrika},
  year    = {1999},
  volume  = {86},
  number  = {1},
  pages   = {169-181},
  doi     = {10.1093/biomet/86.1.169},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\jorgensen_1999.pdf:PDF},
  url     = {https://doi.org/10.1093/biomet/86.1.169},
}

@Article{andrieu_2010,
  author  = {Andrieu, C. and Doucet, A. and Holenstein, R.},
  title   = {Particle Markov Chain Monto Carlo Methods},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year    = {2010},
  volume  = {72},
  number  = {3},
  pages   = {269-342},
  doi     = {10.1111/j.1467-9868.2009.00736.x},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\andrieu_2010.pdf:PDF},
  url     = {https://doi.org/10.1111/j.1467-9868.2009.00736.x},
}

@Article{malik_2011,
  author  = {Malik, S. and Pitt, M.},
  title   = {Particle Filters for Continuous Likelihood Evaluation and Maximization},
  journal = {Journal of Econometrics},
  year    = {2011},
  volume  = {165},
  number  = {2},
  pages   = {190-209},
  doi     = {10.1016/j.jeconom.2011.07.006},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\malik_2011.pdf:PDF},
  url     = {https://doi.org/10.1016/j.jeconom.2011.07.006},
}

@Article{deligiannidis_2018,
  author  = {Deligiannidis, G. and Doucet, A. and Pitt, M.},
  title   = {The Correlated Pseudo-Marginal Method},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year    = {2018},
  volume  = {80},
  number  = {5},
  pages   = {839-870},
  doi     = {10.1111/rssb.12280},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\deligiannidis_2017.pdf:PDF},
  url     = { https://doi.org/10.1111/rssb.12280},
}

@Book{doucet_2001,
  title     = {An Introduction to Sequential Monte Carlo Methods},
  publisher = {Springer-Verlag},
  year      = {2001},
  author    = {Doucet, A. and De Freitas, N. and Gordon, N.},
  file      = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\Doucet_2001.pdf:PDF},
}

@Misc{julia_2012,
  author = {Bezanzon, J. and Karpinski S. and Shah, V. and Edelman, A.},
  title  = {Julia: A Fast Dynamic Language for Technical Computing},
  month  = apr,
  year   = {2012},
  file   = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\julia_2019.pdf:PDF},
}

@Article{jung_2011,
  author  = {Jung, R. C. and Liesenfeld, R. and Richard, J.-F.},
  title   = {Dynamic Factor Models for Multivariate Count Data: An Application to Stock-Market Trading Activity},
  journal = {Journal of Business \& Economic Statistics},
  year    = {2011},
  volume  = {29},
  number  = {1},
  pages   = {73-85},
  month   = jan,
  doi     = {10.2139/ssrn.1169222},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\jung_2011.pdf:PDF},
  url     = {http://doi.org/10.2139/ssrn.1169222 },
}

@Article{quoreshi_2006,
  author  = {Quoreshi, A.M.M.S.},
  title   = {Bivariate Time Series Modeling of Financial Count Data},
  journal = {Communications in Statistics - Theory and Methods},
  year    = {2006},
  volume  = {35},
  number  = {7},
  pages   = {1343-1358},
  month   = sep,
  doi     = {10.1080/03610920600692649},
  file    = {:C\:\\Users\\stapperm\\Dropbox\\arbeit\\Paper\\quoreshi_2006.pdf:PDF},
  url     = {https://doi.org/10.1080/03610920600692649},
}

@Conference{trotter_1956,
  author    = {Trotter, H. F. and Tukey, J. W.},
  title     = {Conditional Monte Carlo for Normal Samples},
  booktitle = {Symposium on Monte Carlo Methods},
  year      = {1956},
  editor    = {Wiley},
  pages     = {64-79},
}

@Book{weiss_2018,
  title     = {An Introduction to Discrete-Valued Time Series},
  publisher = {Wiley {\&} Sons},
  year      = {2018},
  author    = {C. Weiß},
  isbn      = {9781119096962},
  doi       = {10.1002/9781119097013},
  file      = {:C\:\\Users\\stapperm\\sciebo\\Arbeit\\Paper\\weiß_2018.pdf:PDF},
  url       = {http://www.doi.org/10.1002/9781119097013},
}

@Article{weiss_2019,
  author  = {Wei{\ss}, C. H. and Feld, M.H.J.M.},
  title   = {On the performance of information criteria for model identification of count time Series},
  journal = {Studies in Nonlinear Dynamics \& Econometrics},
  year    = {2019},
  volume  = {24},
  number  = {1},
  doi     = {10.1515/snde-2018-0012},
  file    = {:C\:\\Users\\stapperm\\sciebo\\Arbeit\\Paper\\weiss_2019.pdf:PDF},
  url     = {https://doi.org/10.1515/snde-2018-0012},
}

@Article{christou_2014,
  author  = {Christou, V. and Fokianos, K.},
  title   = {Quasi-Likelihood Inference for Negative Binomial Time Series Models},
  journal = {Journal of Time Series Analysis},
  year    = {2014},
  volume  = {34},
  number  = {1},
  pages   = {55-78},
  month   = jan,
  doi     = {10.1111/jtsa.12050},
  file    = {:C\:\\Users\\stapperm\\sciebo\\Arbeit\\Paper\\christou_2014.pdf:PDF},
  url     = {https://doi.org/10.1111/jtsa.12050},
}

@Article{weiss_2019b,
  author  = {Wei{\ss}, C. and Feld, M. and Khan, N. and Sunecher, Y.},
  title   = {INARMA Modeling of Count Time Series},
  journal = {Stats},
  year    = {2019},
  volume  = {2},
  number  = {2},
  pages   = {284-320},
  month   = jun,
  doi     = {10.3390/stats2020022},
  file    = {:C\:\\Users\\stapperm\\sciebo\\Arbeit\\Paper\\weiß_2019b.pdf:PDF},
  url     = {https://doi.org/10.3390/stats2020022},
}

@Article{dungey_2019,
  author  = {Dungey, M. and Martin, V.L. and Tang, C. and Tremayne, A.},
  title   = {A threshold mixed count time series model: estimation and application},
  journal = {Studies in Nonlinear Dynamics \& Econometrics},
  year    = {2019},
  volume  = {24},
  number  = {2},
  doi     = {10.1515/snde-2018-0029},
  file    = {:dungey_2019.pdf:PDF},
  url     = {https://doi.org/10.1515/snde-2018-0029},
}

@Comment{jabref-meta: databaseType:bibtex;}
